{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f74d42",
   "metadata": {},
   "source": [
    "#### HTML의 구조  및 태그\n",
    "- 구조\n",
    " - \\<!Doctype html> : HTML5 문서를 선언하는 구문\n",
    " - \\<html></html> : HTML 문서의 시작과 끝\n",
    " - \\<head></head> : CSS, JavaScript, meta, title 정보들을 설정\n",
    " - \\<body></body> : 실제 홈페이지 화면을 나타내는 부분\n",
    "\n",
    "- 요소 구조\n",
    " - HTML 요소는 여러 속성들을 가질 수 있으며 속성들은 해당 요소에 대한 추가 정보를 제공\n",
    " - 시작 태그\\(< >)로 시작해서 종료 태그(</>)로 끝남\n",
    " - 요소 안에 다른 요소를 작성할 수 있음 \n",
    " <img src = './dataset/html요소구조.jpg' STYLE = 'width:50px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d9671",
   "metadata": {},
   "source": [
    "### HTML 태그\n",
    "- p 태그를 이용하여 문단 작성\n",
    "- h 태그를 이용하여 폰트 크기 설정\n",
    "- ul(unordered list)과 ol(ordered list) 태그로 리스트 작성, 리스트 각각의 요소는 li(항목 나열) 태그로 표시  \n",
    "- table 태그는 thead, tbody를 가질 수 있으며 표를 표현 : tr 행, th(가운데 정렬,굵은 글씨체),td 각 행의 컬럼\n",
    "- input 태그와 button 태그 : 데이터를 넣는 폼과 페이지 조작 버튼 생성\n",
    "- select # select 태그로 선택 리스트 생성\n",
    "- a 태그로 다른 페이지로 이동. 상대경로(내가 있는 경로부터의 경로), 절대경로(항상 같은 url)\n",
    "- img 태그로 이미지 포함 : src(이미지 붙임), alt(이미지 대체)\n",
    "- span 태그로 p태그 처럼 글을 추가. span 태그는 옆으로 나열. br 태그 사용하여 p 태그처럼 사용\n",
    "- div 태그는 화면 레이아웃을 잡는 역할 : 하위 태그들의 영역을 잡아줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6491349",
   "metadata": {},
   "source": [
    "### CSS\n",
    "- CSS로 웹 사이트를 꾸며주기 위해 해당 태그에 접근하는 방식을 크롤러에서도 사용.\n",
    "- selector : CSS로 꾸미기 위해 특정 요소에 접근하는 것을 셀렉터라고 함.\n",
    "- html 파일을 만들었다면 각각의 태그에 다르게 css 를 설정 할 것입니다. 이 때, 어느 요소에 스타일을 적용할지 알려주는 방식이 바로 css 선택자 입니다.\n",
    "- 태그를 이용하여 접근하면 태그는 전부 CSS 효과가 적용\n",
    "- class를 이용하면 원하는 요소만 CSS 효과 적용할 수 있고 원하는 요소만 수집할 수 있음.\n",
    "- id는 class와 다르게 id값이 고유해야 함(id는 한페이지에 하나만 존재해야 함)\n",
    "- 부모 태그와 자식 태그를 나열하여 복잡한 셀렉터를 생성<br>\n",
    "- 참조 url https://ssungkang.tistory.com/entry/css-css-%EC%84%A0%ED%83%9D%EC%9E%90selector-%EC%9D%98-%EC%A2%85%EB%A5%98%EC%99%80-%EC%98%88%EC%8B%9C https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors https://www.nextree.co.kr/p8468/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad4e33",
   "metadata": {},
   "source": [
    "### JavaScript\n",
    "- 웹 사이트의 기능을 넣어줌. script 태그를 이용하여 작성. head or body 하단에 위치\n",
    "- js를 이용하여 HTML 코드를 생성. 크롤러로 분석하기 가장 어려운 부분임\n",
    "- DOM(Document Object Model)이란 HTML을 시각적으로 쉽게 표현하기 위해 만든 객체로 크롤러 만들 때 중요\n",
    "- 데이터를 수집하기 위해 DOM을 이용해 데이터에 접근한 후 해당 데이터 수집\n",
    "- 웹 브라우저는 HTML 코드를 가져온 후 JavaScript를 실행시킨 결과를 보여줌\n",
    "- 소스 보기 페이지에 수집하고자 하는 요소가 없다면 네트워크 탭을 이용, 서버에서 데이터를 받아오는 지 확인\n",
    "- 그렇지 않은 경우 셀레니움을 사용하여 해결<br>\n",
    "- 참조 url http://www.tcpschool.com/javascript/js_dom_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱싱\n",
    "text = 'k=digital training 5기'\n",
    "text1 = 'abc'\n",
    "print(text[0])\n",
    "print(text[-1])\n",
    "print(text1.replace('a','A'))\n",
    "print(text1.capitalize()) # 첫글자만 대문자\n",
    "print(text1.upper()) # 모두 대문자\n",
    "print(text.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6e898",
   "metadata": {},
   "source": [
    "### strip 공백 제거\n",
    "- strip : 양쪽 문자열에 공백이나 인자가된 문자열의 모든 조합을 제거\n",
    "- rstrip : 문자열에 오른쪽 공백이나 인자가된 문자열의 모든 조합을 제거\n",
    "- lstrip : 문자열에 왼쪽 공백이나 인자가된 문자열의 모든 조합을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77baba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' apple'.lstrip())     # 인자가 없을 경우 왼쪽 공백 제거\n",
    "\n",
    "print('apple'.lstrip('ap'))   # 왼쪽으로 a, p의 문자열의 모든 조합을 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('apple '.rstrip())        # 인자가 없을 경우 오른쪽 공백 제거\n",
    "\n",
    "print('apple'.rstrip('lep'))   # 오른쪽으로 l, e, p의 문자열의 모든 조합을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18806099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' apple '.strip())    # 인자가 없을 경우 양쪽 공백 제거\n",
    "\n",
    "print('apple'.strip('ae'))  # 양쪽끝에 a, e의 문자열의 모든 조합을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f71904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제]'K-Digital Training 5기'를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"   <k-digital training 5기>   \"\n",
    "text2 = ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. <k-digital training 5기>; 를 출력하세요\n",
    "print(text1.strip()+text2) # 양쪽 공백 제거 후 이어 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. <k-digital training 5기>   ; 를 출력하세요\n",
    "print(text1.lstrip()+text2) # 왼쪽 공백 제거 후 이어 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131dc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.    <k-digital training 5기>; 를 출력하세요\n",
    "print(text1.rstrip()+text2) # 오른쪽 공백 제거 후 이어 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669673e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<title>k-digital training 5기</title>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. text를 아래와 같이 출력하세요\n",
    "# <div>k-digital training 5기</title>\n",
    "text.replace('<title','<div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a48bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. text를 아래와 같이 출력하세요\n",
    "# <div>k-digital training 5기</div>\n",
    "text.replace('title','div')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe04db",
   "metadata": {},
   "source": [
    "### 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05630b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\g<그룹이름>을 사용하면 정규식의 그룹 이름을 참조할 수 있다.\n",
    "import re\n",
    "data = \"\"\"\n",
    "park 800905-1049118\n",
    "kim  700905-1059119\n",
    "\"\"\"\n",
    "\n",
    "pat = re.compile('(\\d{6})[-]\\d{7}')\n",
    "print(pat.sub('\\g<1>-*******', data))\n",
    "\n",
    "# re.sub(pattern, 바꿀 str, 기존 str)\n",
    "# 기존 str에서 pattern을 찾아 바꿀 str으로 교체하는 함수\n",
    "# pattern에서 group을 지정했다면 바꿀 str에서 <\\\\num>을 사용하여 해당 group의 str을 그대로 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = ('111<head>안녕하세요</head>22')\n",
    "body = re.search('<head>안녕하세요</head>',text) # text에서 <head>안녕하세요</head> 이 부분 search\n",
    "body = body.group()\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b41d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.search('<head>.+</head>',text)\n",
    "a.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = re.compile('[^0-9]+').search(text) # 숫자가 아닌것 1개 이상\n",
    "t.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b241b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = re.search(r'\\D+',text) # 숫자가 아닌 것과 매치, [^0-9]와 동일한 표현식\n",
    "body.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96174872",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = re.compile('[가-힣]+').search(text)\n",
    "body.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.search('안녕하세요',text).group()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<head>안녕하세요...<title>k-digital training 5기</title> 반갑습니다...</head>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. <title>k-digital training 5기</title> 을 출력하세요\n",
    "import re\n",
    "t = re.search('<title>.*</title>',text) \n",
    "print(t.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60250354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. k-digital training 5기 을 출력하세요.\n",
    "# group(0) 매치된 전체 문자열, group(1) 매치된 첫번째 그룹에 해당하는 문자열\n",
    "t = re.search('<title>(.+)</title>', text)\n",
    "t.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.group()\n",
    "t = re.sub('<.+?>','',t) # re.sub(pattern, 바꿀 str, 기존 str)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efece91",
   "metadata": {},
   "source": [
    "### requests 모듈 \n",
    "- pip install requests 명령어로 설치\n",
    "- http는 요청과 응답으로 이루어져 있음\n",
    "- 요청 \n",
    "  - GET : 정보를 가져오기 위해 요청\n",
    "  - POST : 새로운 정보를 보내기 위해 요청\n",
    "  - PUT : 수정할 정보를 보내기 위해 요청\n",
    "  - DELETE : 정보를 삭제하기 위해 요청\n",
    "- 응답\n",
    "  - 1XX : 요청을 받았고 작업 진행 중\n",
    "  - 2XX : 사용자의 요청이 성공적으로 수행됨\n",
    "  - 3XX : 요청은 완료되었으나 리다이렉션이 필요\n",
    "  - 4XX : 사용자의 요청이 잘못됨\n",
    "  - 5XX : 서버 오류가 발생함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1188cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 외장 라이브러리 사용\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "html_data = response.text\n",
    "html_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data.find('네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html_data[365:368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abae797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = re.search('네이버',html_data)\n",
    "content.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content1 = re.search('([가-힣]+)',html_data)\n",
    "content1.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d73df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data.find('<meta property=')\n",
    "print(html_data[390:480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content0 = html_data.split('<meta property=')[0]\n",
    "content1 = html_data.split('<meta property=')[1]\n",
    "print(content0,'\\n')\n",
    "print(content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdf1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = re.search('네이버+',content1)\n",
    "content.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ad1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://search.naver.com/search.naver'\n",
    "params = {'query':'AI'}\n",
    "response = requests.get(URL, params=params)\n",
    "response.status_code\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://comic.naver.com/webtoon/detail'\n",
    "params = {'titleId':784255,'no':29,'weekday':'wed'}\n",
    "response = requests.get(URL,params=params)\n",
    "response.status_code # 온라인 서비스를 HTTP로 호출하면 상태 코드를 응답받게 됩니다.\n",
    "response.text          # 일반적으로 이 상태 코드를 보고 요청이 잘 처리되었는지 문제가 있는지 알 수가 있습니다.\n",
    "                        # 상태 코드는 응답 객체의 status_code 속성을 통해 간단하게 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 네이버 사이트에서 '공지사항' 출력(파이썬 인덱싱, 함수 / 정규표현식)\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "naver = response.text\n",
    "t = re.search('공지사항',naver)\n",
    "t.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://naver.com'\n",
    "res = requests.get(url) # url얻기\n",
    "res.status_code\n",
    "r = res.text\n",
    "\n",
    "# 인덱싱\n",
    "rr = r.find('공지사항')\n",
    "display(rr, r[rr:(rr+4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dec747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 홈페이지에 있는 ['메일','카페','블로그','지식iN','쇼핑']을 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "naver = response.text\n",
    "soup = BeautifulSoup(naver,'html.parser')\n",
    "a = soup.select('#NM_FAVORITE > div.group_nav > ul.list_nav.type_fix > li.nav_item> a',limit=5)\n",
    "li = []\n",
    "for i in a:\n",
    "    li.append(i.text)\n",
    "li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fccda",
   "metadata": {},
   "source": [
    "### BeautifulSoup 모듈\n",
    "\n",
    "- 홈페이지 내 데이터를 쉽게 추출할 수 있게 해주는 파이썬 외부 라이브러리\n",
    "- 웹 문서 내 수많은 HTML 태그들을 parser를 활용해 사용하기 편한 파이썬 객체로 만들어 제공\n",
    "- 웹 문서 구조를 알고 있다면 편하게 데이터를 뽑아 활용할 수 있음\n",
    "- BS는 HTML 문서를 태그를 기반으로 구조화하여 태그로 원하는 데이터를 찾아가는 형식\n",
    "\n",
    "- find() : HTML의 해당 태그에 대한 첫번째 정보를 가져옴\n",
    "  - find(속성='값') : HTML 해당 속성과 일치하는 값에 대한 첫번째 정보를 가져옴\n",
    "- find_all(), findAll\n",
    "  - HTML의 해당 태그에 대한 모든 정보를 리스트 형식으로 가져옴. limit 옵션으로 개수 지정 가능\n",
    "  - CSS 속성으로 필터링(class_로 클래스를 직접 사용 혹은 attrs에서 속성 = 값으로 필터링)\n",
    "- select_one(), select()\n",
    "  - CSS 선택자를 활용하여 원하는 정보를 가져옴(태그를 검색하는 find, find_all과 비슷함)\n",
    "  - class는 점(.)으로, id는 #로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html lang=\"en\">\n",
    "<head><title>crawl</title></head>\n",
    "<body>\n",
    "<p class=\"a\" align=\"center\"> text1</p>\n",
    "<p class=\"b\" align=\"center\"> text2</p>\n",
    "<p class=\"c\" align=\"center\"> text3</p>\n",
    "<div><img src=\"/source\" width=\"300\" height=\"200\"></div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser') # html문서처럼 구조화 시켜줌\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ac3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://naver.com'\n",
    "req = requests.get(URL)\n",
    "html = req.text\n",
    "html.find('blind')\n",
    "html[9800:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')\n",
    "result = soup.find(class_='blind')\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fadba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1 id=\"title\">스크레이핑이란?</h1>\n",
    "  <p id = \"body\">웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "  <p>원하는 부분을 하나 더 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "body = soup.find(id = \"body\")\n",
    "title = soup.find(id = 'title')\n",
    "body.text # 출력 --> 웹 페이지를 분석하는것\n",
    "title.string # 출력 --> 스크래핑이란?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b97e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = soup.html.body.h1.string\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = soup.html.body.p\n",
    "p1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "texts = soup.find_all('p') # 태그 p 모두 찾기\n",
    "for text in texts: # for문 돌려서 p태그 안에 있는 텍스트 찾기\n",
    "    print(text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6487f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "links = soup.find_all('a') # 리스트형태로 반환되므로 출력시 for문 사용\n",
    "# links\n",
    "for a in links:\n",
    "    print(a.text,'>', a.get('href')) # a에서의 text만 a에서의 href 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req # 내장 라이브러리\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "title = soup.find('title').string # title 문자열로 반환\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "title = soup.find('title').string\n",
    "wf = soup.find('wf').string # find(name, attrs, recursive, string, **kwargs)\n",
    "                # 조건에 맞는 태그를 가져옵니다. 만약 조건에 맞는 태그가 1개 이상이면 가장 첫 번째 태그를 가져옵니다.\n",
    "print(title,'\\n')\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4와 정규표현식 활용\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf = soup.find('wf').text\n",
    "' '.join(re.findall('[0-9가-힣]+',wf)) # findall -> HTML의 해당 태그에 대한 모든 정보를 리스트 형식으로 가져오기 때문에\n",
    "                                                # ' '.join함수 써서 이어줌 -> 매끄럽게 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 \n",
    "# ?는 ?앞의 문자(범위)가 0개 또는 1개인지 판단하고, .은 .이 있는 위치에 아무 문자(숫자)가 1개 있는지 판단\n",
    "text = re.findall('[^ a-zA-Z0-9]?[0-9가-힣]+[^ a-zA-Z0-9]?',wf)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf = soup.find('wf').text\n",
    "text = ''.join(re.findall('[^A-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] wf 태그는 모두 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://naver.com'\n",
    "text = requests.get(url).text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url = 'https://naver.com'\n",
    "response = urllib.request.urlopen(url)\n",
    "byte_data = response.read()\n",
    "html = byte_data.decode('utf-8')\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "print(soup.find('a'))\n",
    "print(soup.find(class_='blind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8544e8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 모든 a 태그 검색. 접근시 html_as[0], [1], .. 첫번째가 0인덱스\n",
    "soup.find_all('a', limit=2)  # a태그 두 개만 가져옴.\n",
    "soup.find_all('a', limit=2)[0] # 두개 가져온것 중에서 0번째 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81788648",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span',class_='blind')[0:3] # 인덱스 0~2까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cee76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span', class_=['blind',\"ico_arr\"])[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea63f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span',attrs={'class':'blind'})[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(string='네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all(string=re.compile('네이버'))) # 네이버 들어간거 모두 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"http://movie.naver.com\")\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "text = soup.find('span', attrs={'class':'blind'}) # attrs는 dict로 되어 있다. dict로 적용해야 원하는 요청을 리턴할 수 있음\n",
    "print(text)\n",
    "print(text.get_text()) # 태그사이에 있는 내용 출력\n",
    "print(text.get('class')) # 클래스명 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "h1 = soup.select_one('div#meigen > h1').string # 하나만 선택--> find랑 같음\n",
    "h1 #  id가 meigen의 h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b6660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup(요청결과의 내용, '파싱할 대상 type(html, xml, json)' , 인코딩타입)\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "li = soup.select('div#meigen >ul.items> li')\n",
    "for i in li: # li가 3개이므로 for문 돌려서 출력해줘야함\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30676ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = soup.select(\"div#meigen > ul > li\") # ul이 하나이므로 .iems 안붙여줘도 가능\n",
    "for i in li:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = soup.select('div#meigen > ul.items > li')\n",
    "for li in items:\n",
    "    print(li.string) # li.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd00800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 네이버 환율(원화/USD) 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "html = requests.get(url).text\n",
    "s = BeautifulSoup(html,'html.parser')\n",
    "a = s.find('span',class_=['value']) # <span> 태그에 class명이 value인것 찾기\n",
    "# for i in a:\n",
    "#     print(f'{i,text}', end='')\n",
    "print('usd/krw = ',a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "\n",
    "price = soup.select_one('#exchangeList > li.on > a.head.usd > div >span.value').string\n",
    "print('usd/krw = ', price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5aac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3, 6, 9, 12 번째(3의배수) 배경변경 \n",
    "li:nth-child(3n){ background: red; } \n",
    "    \n",
    "#10번째 부터 이후 모든 리스트 컬러변경 \n",
    "li:nth-child(n+10) { color: blue; } \n",
    "\n",
    "# 1번째 부터 5번째 까지 배경변경 \n",
    "li:nth-child(-n+5) { background: green; }\n",
    "    \n",
    "# 15번째 부터 20번째 까지 배경변경 \n",
    "li:nth-child(n+15):nth-child(-n+20) { background: hotpink; } \n",
    "        \n",
    "# 끝에서 부터 3번째 \n",
    "li:nth-last-child(3) { background: gold; } \n",
    "    \n",
    "# 홀수 \n",
    "li:nth-child(odd) { color: red; } \n",
    "    \n",
    "#짝수  \n",
    "li:nth-child(even) { color: red; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b84828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    " \n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "\n",
    "price = soup.select_one('#exchangeList > li:nth-child(3) > a.head.eur > div > span.value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a10654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 영화 랭킹 가져와서 첫번째 영화제목을 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a63592",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cnt&date=20220208'\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "movie_top1 = soup.select_one('div.tit3 > a')\n",
    "movie_top1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 네이버 영화 랭킹 가져와서 전체 영화제목을 출력하세요\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cnt&date=20220208'\n",
    "res = requests.get(url).text # 응답 데이터(텍스트형식 내용, 텍스트 파일에 씀)\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "movie_top = soup.select('#old_content > table > tbody > tr> td.title> div> a')\n",
    "for i, m in enumerate(movie_top):\n",
    "    print(f'No.{i+1} : {m.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 기상청 육상 정보에서 강원도의 지역번호는 105이다. 강원도의 날씨예보를 출력하세요.\n",
    "# url = 'https://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=105'\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "api = 'https://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "\n",
    "values = {\n",
    "    'stnId':'105'\n",
    "}\n",
    "params = urllib.parse.urlencode(values)\n",
    "url = api + \"?\" + params\n",
    "print(\"url\", url)\n",
    "\n",
    "res = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf = soup.find('wf').string\n",
    "text = ''.join(re.findall('[^A-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40822ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 관심 내용에 대하여 웹에서 가져와서 정규표현식, BS를 이용하여 데이터를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<head>\n",
    "    <title>crawler</title>\n",
    "</head>\n",
    "<body>\n",
    "    <p class=\"a\" align=\"center\"> text1</p>\n",
    "    <p class=\"b\" align=\"center\"> text2</p>\n",
    "    <p class=\"c\" align=\"center\"> text3</p>\n",
    "    <div>\n",
    "        <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "contents = soup.find('body')\n",
    "contents # body 태그 안에 있는 태그들 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 vs 자손\n",
    "# for child in contents.children:\n",
    "#     print(child)\n",
    "for d in contents.descendants:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f80ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tag = contents.find('img')\n",
    "# print(img_tag,'\\n')\n",
    "print(img_tag.parent) # img 감싸고 있는 div 태그까지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조상\n",
    "list(img_tag.parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_tag.find_parent('body'), '\\n')\n",
    "print(img_tag.find_parent('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags = soup.find_all('p')\n",
    "p_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tag = soup.find_all('p',class_=['b','c'])\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tag = soup.find_all('p', attrs ={'class': {'b','c'}})\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb359973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모 다루기 \n",
    "# 앞에 있는 형제 요소를 선택하기 위해서는 previous_sibling\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.pythonscraping.com/pages/page3.html'\n",
    "url_req = requests.get(url)\n",
    "html = url_req.text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.find('img',  \n",
    "             {'src':'../img/gifts/img1.jpg'}).parent.previous_sibling.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pythonscraping.com/pages/page3.html'\n",
    "req = requests.get(url)\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "img = soup.select_one('#gift5 > td:nth-child(4) > img') # id가 gift5 중에서 4번째 인덱스의 img 선택\n",
    "print(img.parent.previous_sibling.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbe1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://naver.com')\n",
    "html = html.text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "hlists = bs.findAll({'h1','h2','h3','h4','h5','h6'})\n",
    "for h in hlists:\n",
    "    print(h,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86168756",
   "metadata": {},
   "outputs": [],
   "source": [
    "hlists = bs.find({'h1','h2','h3','h4','h5','h6'}, text='뉴스스탠드')\n",
    "hlists.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5cf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttls = bs.findAll(id = 'NM_NEWSSTAND_TITLE')\n",
    "for t in ttls:\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dataq.or.kr/www/sub/a_07.do'\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = soup.findAll(id='tab1')\n",
    "texts = soup.select('#tab1')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://www.dataq.or.kr/www/sub/a_07.do').text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "a = soup.find(id='tab1').text\n",
    "\n",
    "print(re.sub('\\n\\n', '', a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fadb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제] 아래와 같이 원본 데이터를 유지하면서 빈줄 없이 출력하세요.\n",
    "국가기술자격\n",
    "관련 근거\n",
    "국가기술자격법 및 동법 시행령\n",
    "빅데이터분석기사 정의\n",
    "빅데이터 이해를 기반으로 빅데이터 분석 기획, 빅데이터 수집·저장·처리, 빅데이터 분석 및 시각화를 수행하는 실무자를 말한다.\n",
    "빅데이터분석기사의 필요성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전쟁과 평화\n",
    "\n",
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97601770",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = bs.find(id='text')\n",
    "# print(d1.text)\n",
    "d2 = bs.findAll('span',{'class':{'red','green'}})\n",
    "for i,d in enumerate(d2):\n",
    "    print(f'No.{i+1} : \\n {d.text}', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 전쟁과 평화에 등장하는 모든 고유명사을 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "url_req = requests.get(url).text\n",
    "bs = BeautifulSoup(url_req,'html.parser')\n",
    "# bs\n",
    "d2 = bs.findAll('span',{'class':'green'})\n",
    "# list(d2)\n",
    "\n",
    "for d in d2:\n",
    "    print(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "url_req = requests.get(url).text\n",
    "bs = BeautifulSoup(url_req,'html.parser')\n",
    "d2 = bs.findAll('span',{'class':'green'})\n",
    "\n",
    "def check(text):\n",
    "    checking = ('the','The','her','Her','his','His','its','Its')\n",
    "    checking2 = (\"'s\")\n",
    "    if text.startswith(checking) == False and text.endswith(checking2) == False:\n",
    "        print(text)\n",
    "\n",
    "for i in d2:\n",
    "    i = i.text.replace('\\n','')\n",
    "    check(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eef927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 + bs4\n",
    "url = 'http://www.pythonscraping.com/pages/page3.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "images =  bs.findAll('img')\n",
    "list(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e85dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "images = bs.findAll('img', {'src':re.compile('\\.\\.\\/img.*jpg')})\n",
    "for image in images:\n",
    "    print(image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81012060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 이용\n",
    "spans = bs.findAll('span')\n",
    "list(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.find_all(lambda tag: tag.get_text() == \"Or maybe he's only resting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dcfb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 가능한 모든 방법으로 Numbers를 출력하세요(10개 이상) \n",
    "fp = open('books.html', encoding='utf-8')\n",
    "soup = BeautifulSoup(fp,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱싱\n",
    "print(soup.select('li')[3].string)\n",
    "print(soup.find_all('li')[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdeb40c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20776/3128831309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#nu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# io로 접근\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'li#nu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# li의 id로 접근\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ul> li#nu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ul 밑에 잇는 li의 id nu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20776/3128831309.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#nu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# io로 접근\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# lambda 사용\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "sel = lambda q : print(soup.select_one(q).string)\n",
    "\n",
    "sel('#nu') # io로 접근\n",
    "sel('li#nu') # li의 id로 접근\n",
    "sel('ul> li#nu') # ul 밑에 잇는 li의 id nu\n",
    "sel('#bible #nu') # ul id 에서 li id\n",
    "sel('#bible > #nu')\n",
    "sel('ul#bible > li#nu')\n",
    "sel(\"li[id='nu']\") # \"' '\" 쉼표 주의\n",
    "sel(\"li:nth-of-type(4)\") # th-of-type의 경우 부모 요소의 모든 자식 요소 중 ①type 조건을 만족하고 ②순서를 만족하는 대상을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(id='nu').text)\n",
    "print(soup.select('li')[3].text)\n",
    "print(soup.find('li',id='nu').text)\n",
    "print(soup.select_one('li#nu').text)\n",
    "print(soup.find(lambda tag: tag.get_text()=='Numbers').text)\n",
    "print(list(soup.find('ul').children)[2]) ## 이해안감\n",
    "# print(list(soup.find('ul').children)[1])\n",
    "# print(list(soup.find('ul').children)[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
